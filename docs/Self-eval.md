# Self-Evaluation

1. **Repository**: [https://github.com/unige-vizis/vizis](https://github.com/unige-vizis/vizis)

2. **Live Site**: [https://unige-vizis.github.io/vizis/](https://unige-vizis.github.io/vizis/)

3. **Self-Evaluation**
   - **Maleah**: I have HTML and CSS knowledge, but I never used Github.
   - **Victoria**: I have basic knowledge of HTML and CSS, which I have used for some university projects. However, my understanding of both languages is still very limited, as I have usually worked with the support of classmates who have more experience in this area.
   - **Kim**: I have not yet created my own complete website, but during school I participated in a "Homepage" working group where I gained first insights into web design. My experience with HTML, CSS and JavaScript is therefore at a beginner level but I am very interested in learning how to create websites and apply data visualization techniques. My strength are in working with data and explaining results clearly.
   - **Matteo**: I developed a website featuring an interactive visualization of the B-Tree structure and related algorithms using the React framework and the react-d3-tree library/component. [https://dbis-btree.uibk.ac.at/](https://dbis-btree.uibk.ac.at/)
     - Some experience with HTML, JavaScript, CSS, and the React framework
     - Some experience with d3 for tree visualizations
   - **Petula**: I have experiences with HTML, JS and databases due to several jobs. I also have a few experience with vue.js due to a uni project, but I never worked with d3.js.

4. **Technologies**: HTML, JS, d3.js, vue.js

5. **Data Handling**: As a baseline, we will work with the original CSV files. We process them using Python and classic libraries like pandas and NumPy. From there, we create static visualisations directly in Python (Matplotlib/seaborn) and upload the PNGs, or we create reduced "viz-datasets", preferably in JSON format for easy usage in D3, that we can upload to our website easily and hook up to interactive visualisations. When available, we might make use of APIs, such as in the case of ACLED, obtaining the required small data requests directly and up to date in JSON.
   Python scripts will follow a pipeline-like structure, probably in .ipynb and transformations on datasets will be versioned and applied within new files.
