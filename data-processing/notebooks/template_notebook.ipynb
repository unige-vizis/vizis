{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Template\n",
    "\n",
    "**Purpose**: [Describe what this notebook does]\n",
    "\n",
    "**Input**: [Source data files]\n",
    "\n",
    "**Output**: [What this notebook produces]\n",
    "\n",
    "**Date**: [YYYY-MM-DD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualizations (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from raw-data folder\n",
    "raw_data_path = Path('../raw-data')\n",
    "\n",
    "# Example: Load CSV\n",
    "# df = pd.read_csv(raw_data_path / 'your_data.csv')\n",
    "\n",
    "# Example: Load Excel\n",
    "# df = pd.read_excel(raw_data_path / 'your_data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Display basic info\n",
    "# print(f\"Shape: {df.shape}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "# df.isnull().sum()\n",
    "\n",
    "# Check data types\n",
    "# df.dtypes\n",
    "\n",
    "# Basic statistics\n",
    "# df.describe()\n",
    "\n",
    "# Check for duplicates\n",
    "# df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example transformations:\n",
    "\n",
    "# Remove duplicates\n",
    "# df_clean = df.drop_duplicates()\n",
    "\n",
    "# Handle missing values\n",
    "# df_clean = df_clean.dropna(subset=['important_column'])\n",
    "# df_clean['column'] = df_clean['column'].fillna(0)\n",
    "\n",
    "# Convert data types\n",
    "# df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "# df_clean['value'] = df_clean['value'].astype(float)\n",
    "\n",
    "# Filter data\n",
    "# df_clean = df_clean[df_clean['year'] >= 2020]\n",
    "\n",
    "# Create new columns\n",
    "# df_clean['year'] = df_clean['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Intermediate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to intermediate folder\n",
    "intermediate_path = Path('../intermediate')\n",
    "intermediate_path.mkdir(exist_ok=True)\n",
    "\n",
    "# df_clean.to_csv(intermediate_path / 'cleaned_data.csv', index=False)\n",
    "# print(f\"Saved cleaned data: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregate for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example aggregations:\n",
    "\n",
    "# Group by category\n",
    "# summary = df_clean.groupby('category').agg({\n",
    "#     'value': ['sum', 'mean', 'count']\n",
    "# }).reset_index()\n",
    "\n",
    "# Time series aggregation\n",
    "# time_series = df_clean.groupby('date').agg({\n",
    "#     'value': 'sum'\n",
    "# }).reset_index()\n",
    "\n",
    "# Top N items\n",
    "# top_10 = df_clean.nlargest(10, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Reduced Dataset for D3.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for web visualization\n",
    "# Keep only necessary columns\n",
    "# viz_data = summary[['category', 'value', 'count']].copy()\n",
    "\n",
    "# Convert dates to ISO format strings\n",
    "# viz_data['date'] = viz_data['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Round numbers to reduce file size\n",
    "# viz_data['value'] = viz_data['value'].round(2)\n",
    "\n",
    "# Check size\n",
    "# print(f\"Rows in viz dataset: {len(viz_data)}\")\n",
    "# print(f\"Columns: {viz_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Dataset for Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to viz-datasets (this will be committed to git)\n",
    "viz_datasets_path = Path('../viz-datasets')\n",
    "viz_datasets_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert to JSON\n",
    "# output_file = viz_datasets_path / 'your_dataset.json'\n",
    "# viz_data_dict = viz_data.to_dict('records')\n",
    "\n",
    "# with open(output_file, 'w') as f:\n",
    "#     json.dump(viz_data_dict, f, indent=2)\n",
    "\n",
    "# Check file size\n",
    "# file_size = output_file.stat().st_size / 1024  # KB\n",
    "# print(f\"Saved: {output_file.name}\")\n",
    "# print(f\"File size: {file_size:.2f} KB\")\n",
    "# if file_size > 1000:\n",
    "#     print(\"⚠️ Warning: File is larger than 1MB. Consider further reduction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Static Visualizations (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create charts for static images\n",
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# viz_data.plot(x='category', y='value', kind='bar', ax=ax)\n",
    "# plt.title('Your Chart Title')\n",
    "# plt.xlabel('Category')\n",
    "# plt.ylabel('Value')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Save to output folder\n",
    "# output_path = Path('../output')\n",
    "# output_path.mkdir(exist_ok=True)\n",
    "# fig.savefig(output_path / 'chart.png', dpi=300, bbox_inches='tight')\n",
    "# print(\"Chart saved to output folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of what was created\n",
    "# print(\"=\"*50)\n",
    "# print(\"PROCESSING COMPLETE\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"Input rows: {len(df)}\")\n",
    "# print(f\"Output rows: {len(viz_data)}\")\n",
    "# print(f\"Reduction: {(1 - len(viz_data)/len(df))*100:.1f}%\")\n",
    "# print(\"\\nNext steps:\")\n",
    "# print(\"1. Copy JSON from viz-datasets/ to public/src/assets/data/\")\n",
    "# print(\"2. Import in Vue component and use with D3.js\")\n",
    "# print(\"3. (Optional) Copy PNG from output/ to public/src/assets/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
